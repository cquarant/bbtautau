{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Fit and Limit Analysis Report\n",
    "\n",
    "This notebook analyzes the results from HiggsCombine fits, extracting:\n",
    "- Asymptotic limits and their uncertainties\n",
    "- Fit convergence status\n",
    "- Nuisance parameter pulls and constraints\n",
    "- Summary statistics across multiple card directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from pathlib import Path\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set up plotting with CMS style\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# CARDS_BASE_DIR =  \"/home/users/lumori/bbtautau/src/bbtautau/cards/25July31/nobbttpresel_noNormSig_noBkgConstraint_ParT\"\n",
    "# CARDS_BASE_DIR =  \"/home/users/lumori/bbtautau/src/bbtautau/cards/25July31/lowregBDT\"\n",
    "CARDS_BASE_DIR = \"/home/users/lumori/bbtautau/src/bbtautau/cards/25Aug4_replayMay26Cuts\"\n",
    "CHANNELS = [\"combined\", \"hh\", \"he\", \"hm\"]\n",
    "\n",
    "\n",
    "# Find all card directories with outputs\n",
    "def find_output_directories():\n",
    "    \"\"\"Find all directories containing analysis outputs\"\"\"\n",
    "    output_dirs = []\n",
    "\n",
    "    for root, dirs, files in os.walk(CARDS_BASE_DIR):\n",
    "        if \"outs\" in dirs:\n",
    "            outs_path = Path(root) / \"outs\"\n",
    "            if any(outs_path.glob(\"*.txt\")):\n",
    "                output_dirs.append(root)\n",
    "\n",
    "    return sorted(output_dirs)\n",
    "\n",
    "\n",
    "output_dirs = find_output_directories()\n",
    "print(f\"Found {len(output_dirs)} directories with outputs:\")\n",
    "for d in output_dirs:\n",
    "    print(f\"  - {Path(d).relative_to(CARDS_BASE_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_asymptotic_limits(file_path):\n",
    "    \"\"\"Parse asymptotic limits from log file\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    if not Path(file_path).exists():\n",
    "        return results\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Look for expected limits pattern\n",
    "        patterns = {\n",
    "            \"expected_2.5\": r\"Expected\\s+2\\.5%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"expected_16.0\": r\"Expected\\s+16\\.0%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"expected_50.0\": r\"Expected\\s+50\\.0%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"expected_84.0\": r\"Expected\\s+84\\.0%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"expected_97.5\": r\"Expected\\s+97\\.5%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"observed\": r\"Observed\\s+Limit:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "        }\n",
    "\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, content, re.IGNORECASE)\n",
    "            if match:\n",
    "                results[key] = float(match.group(1))\n",
    "\n",
    "        # Check for convergence issues\n",
    "        convergence_issues = []\n",
    "        if \"Minimization did NOT converge\" in content:\n",
    "            convergence_issues.append(\"did_not_converge\")\n",
    "\n",
    "        results[\"convergence_issues\"] = convergence_issues\n",
    "        results[\"status\"] = \"success\" if not convergence_issues else \"issues\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "        results[\"status\"] = \"parse_error\"\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def parse_background_fit(file_path):\n",
    "    \"\"\"Parse background fit results\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    if not Path(file_path).exists():\n",
    "        return results\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Check fit status\n",
    "        if \"Minimization success!\" in content:\n",
    "            results[\"fit_converged\"] = True\n",
    "        elif \"Minimization did NOT converge\" in content:\n",
    "            results[\"fit_converged\"] = False\n",
    "        else:\n",
    "            results[\"fit_converged\"] = None\n",
    "\n",
    "        # Extract fit statistics\n",
    "        nll_match = re.search(r\"best fit NLL\\s*=\\s*([0-9.-]+)\", content)\n",
    "        if nll_match:\n",
    "            results[\"best_fit_nll\"] = float(nll_match.group(1))\n",
    "\n",
    "        # Count function calls\n",
    "        fcn_calls = len(re.findall(r\"FCN\", content))\n",
    "        results[\"function_calls\"] = fcn_calls\n",
    "\n",
    "        # Check for specific issues\n",
    "        issues = []\n",
    "        if \"Hesse matrix not pos-def\" in content:\n",
    "            issues.append(\"hesse_not_posdef\")\n",
    "        if \"MIGRAD FAILS\" in content:\n",
    "            issues.append(\"migrad_failed\")\n",
    "        if \"Covariance matrix\" in content and \"not available\" in content:\n",
    "            issues.append(\"no_covariance\")\n",
    "\n",
    "        results[\"fit_issues\"] = issues\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing background fit {file_path}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test parsing on first directory\n",
    "if output_dirs:\n",
    "    test_dir = Path(output_dirs[0]) / \"outs\"\n",
    "    print(f\"Testing parsing on: {test_dir}\")\n",
    "\n",
    "    # Look for limit files\n",
    "    limit_files = list(test_dir.glob(\"*AsymptoticLimits.txt\"))\n",
    "    if limit_files:\n",
    "        test_results = parse_asymptotic_limits(limit_files[0])\n",
    "        print(f\"Sample limit parsing: {test_results}\")\n",
    "\n",
    "    # Look for background fit files\n",
    "    bfit_files = list(test_dir.glob(\"*MultiDimFit.txt\"))\n",
    "    if bfit_files:\n",
    "        test_bfit = parse_background_fit(bfit_files[0])\n",
    "        print(f\"Sample background fit parsing: {test_bfit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_results():\n",
    "    \"\"\"Collect results from all output directories\"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    for card_dir in output_dirs:\n",
    "        outs_dir = Path(card_dir) / \"outs\"\n",
    "        card_name = Path(card_dir).relative_to(CARDS_BASE_DIR)\n",
    "\n",
    "        print(f\"Processing: {card_name}\")\n",
    "\n",
    "        # Check for different channel results\n",
    "        for channel in CHANNELS:\n",
    "            result_entry = {\"card_directory\": str(card_name), \"channel\": channel}\n",
    "\n",
    "            # Look for limits file\n",
    "            if channel == \"combined\":\n",
    "                limit_file = outs_dir / \"AsymptoticLimits.txt\"\n",
    "                bfit_file = outs_dir / \"MultiDimFit.txt\"\n",
    "            else:\n",
    "                limit_file = outs_dir / f\"{channel}AsymptoticLimits.txt\"\n",
    "                bfit_file = outs_dir / f\"{channel}MultiDimFit.txt\"\n",
    "\n",
    "            # Parse limits\n",
    "            limit_results = parse_asymptotic_limits(limit_file)\n",
    "            result_entry.update(limit_results)\n",
    "\n",
    "            # Parse background fit\n",
    "            bfit_results = parse_background_fit(bfit_file)\n",
    "            result_entry.update(bfit_results)\n",
    "\n",
    "            # Only add if we found some results\n",
    "            if limit_results or bfit_results:\n",
    "                all_results.append(result_entry)\n",
    "\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "# Collect all results\n",
    "results_df = collect_all_results()\n",
    "print(f\"\\nCollected results from {len(results_df)} analyses\")\n",
    "print(f\"Columns: {list(results_df.columns)}\")\n",
    "print(f\"\\nFirst few entries:\")\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=== ANALYSIS SUMMARY ===\")\n",
    "print(f\"Total analyses: {len(results_df)}\")\n",
    "print(f\"Card directories: {results_df['card_directory'].nunique()}\")\n",
    "print(f\"Channels analyzed: {sorted(results_df['channel'].unique())}\")\n",
    "\n",
    "# Status summary\n",
    "if \"status\" in results_df.columns:\n",
    "    print(\"\\n=== LIMIT CALCULATION STATUS ===\")\n",
    "    status_counts = results_df[\"status\"].value_counts()\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"{status}: {count}\")\n",
    "\n",
    "# Convergence summary\n",
    "if \"fit_converged\" in results_df.columns:\n",
    "    print(\"\\n=== BACKGROUND FIT CONVERGENCE ===\")\n",
    "    conv_counts = results_df[\"fit_converged\"].value_counts()\n",
    "    for conv, count in conv_counts.items():\n",
    "        print(f\"{conv}: {count}\")\n",
    "\n",
    "# Expected limits summary\n",
    "if \"expected_50.0\" in results_df.columns:\n",
    "    limits_summary = results_df.groupby(\"channel\")[\"expected_50.0\"].agg(\n",
    "        [\"count\", \"mean\", \"std\", \"min\", \"max\"]\n",
    "    )\n",
    "\n",
    "    # Clean up channel names and column names\n",
    "    channel_name_map = {\"combined\": \"Combined\", \"hh\": \"œÑ_h œÑ_h\", \"he\": \"œÑ_h e\", \"hm\": \"œÑ_h Œº\"}\n",
    "\n",
    "    limits_summary.index = [channel_name_map.get(idx, idx) for idx in limits_summary.index]\n",
    "    limits_summary.columns = [\"Count\", \"Mean\", \"Std Dev\", \"Min\", \"Max\"]\n",
    "\n",
    "    print(\"\\n=== EXPECTED LIMITS (50%) BY CHANNEL ===\")\n",
    "    display(limits_summary.round(2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Detailed Results Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate transposed tables for each channel\n",
    "print(\"=== DETAILED RESULTS BY CHANNEL ===\")\n",
    "\n",
    "# Get available columns\n",
    "limit_cols = [\"expected_2.5\", \"expected_16.0\", \"expected_50.0\", \"expected_84.0\", \"expected_97.5\"]\n",
    "available_limit_cols = [col for col in limit_cols if col in results_df.columns]\n",
    "\n",
    "status_cols = [\"status\", \"fit_converged\"]\n",
    "available_status_cols = [col for col in status_cols if col in results_df.columns]\n",
    "\n",
    "# Create table for each channel\n",
    "channels = sorted(results_df[\"channel\"].unique())\n",
    "\n",
    "# Define nice column names\n",
    "column_name_map = {\n",
    "    \"expected_2.5\": \"Expected -2œÉ\",\n",
    "    \"expected_16.0\": \"Expected -1œÉ\",\n",
    "    \"expected_50.0\": \"Expected Median\",\n",
    "    \"expected_84.0\": \"Expected +1œÉ\",\n",
    "    \"expected_97.5\": \"Expected +2œÉ\",\n",
    "    \"status\": \"Status\",\n",
    "    \"fit_converged\": \"Fit Converged\",\n",
    "}\n",
    "\n",
    "# Define nice channel names\n",
    "channel_name_map = {\"combined\": \"Combined\", \"hh\": \"œÑ_h œÑ_h\", \"he\": \"œÑ_h œÑ_e\", \"hm\": \"œÑ_h œÑ_Œº\"}\n",
    "\n",
    "for channel in channels:\n",
    "    channel_data = results_df[results_df[\"channel\"] == channel].copy()\n",
    "\n",
    "    if len(channel_data) > 0:\n",
    "        # Select columns for this channel (excluding 'channel' since it's the same for all rows)\n",
    "        summary_cols = [\"card_directory\"] + available_limit_cols + available_status_cols\n",
    "        summary_table = channel_data[summary_cols].copy()\n",
    "\n",
    "        # Format the table - round to 2 decimal places\n",
    "        for col in available_limit_cols:\n",
    "            if col in summary_table.columns:\n",
    "                summary_table[col] = summary_table[col].round(2)\n",
    "\n",
    "        # Clean up card_directory names (remove underscores, make prettier)\n",
    "        summary_table[\"card_directory\"] = (\n",
    "            summary_table[\"card_directory\"].str.replace(\"_\", \" \").str.title()\n",
    "        )\n",
    "\n",
    "        # Transpose the table: set card_directory as index, then transpose\n",
    "        transposed_table = summary_table.set_index(\"card_directory\").T\n",
    "\n",
    "        # Rename the index (row names) to be more readable\n",
    "        transposed_table.index = [\n",
    "            column_name_map.get(idx, idx.replace(\"_\", \" \").title())\n",
    "            for idx in transposed_table.index\n",
    "        ]\n",
    "        # Remove the index name to avoid showing \"card_directory\" in top left\n",
    "        # transposed_table.index.name = \"\"\n",
    "\n",
    "        channel_display_name = channel_name_map.get(channel, channel.upper())\n",
    "        print(f\"\\n=== {channel_display_name} Channel ===\")\n",
    "        display(transposed_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot expected limits comparison\n",
    "if \"expected_50.0\" in results_df.columns and len(results_df) > 1:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # 1. Expected limits by channel\n",
    "    ax1 = axes[0, 0]\n",
    "    channel_data = results_df.dropna(subset=[\"expected_50.0\"])\n",
    "    if len(channel_data) > 0:\n",
    "        # Create boxplot using matplotlib\n",
    "        channels = sorted(channel_data[\"channel\"].unique())\n",
    "        box_data = [\n",
    "            channel_data[channel_data[\"channel\"] == ch][\"expected_50.0\"].values for ch in channels\n",
    "        ]\n",
    "\n",
    "        bp = ax1.boxplot(box_data, labels=channels, patch_artist=True)\n",
    "        # Color boxes with CMS-style colors\n",
    "        colors = plt.cm.Set2(np.linspace(0, 1, len(channels)))\n",
    "        for patch, color in zip(bp[\"boxes\"], colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "\n",
    "        ax1.set_title(\"Expected Limits (50%) by Channel\", fontsize=14)\n",
    "        ax1.set_ylabel(\"Expected Limit (r < X)\", fontsize=12)\n",
    "        ax1.tick_params(axis=\"x\", rotation=45)\n",
    "        hep.cms.label(loc=0, ax=ax1, fontsize=10)\n",
    "\n",
    "    # 2. Expected limits by card directory\n",
    "    ax2 = axes[0, 1]\n",
    "    if len(channel_data) > 0:\n",
    "        # Only show if we have multiple directories\n",
    "        if channel_data[\"card_directory\"].nunique() > 1:\n",
    "            # Create grouped bar plot\n",
    "            directories = sorted(channel_data[\"card_directory\"].unique())\n",
    "            channels = sorted(channel_data[\"channel\"].unique())\n",
    "\n",
    "            x = np.arange(len(directories))\n",
    "            width = 0.8 / len(channels)\n",
    "            colors = plt.cm.Set2(np.linspace(0, 1, len(channels)))\n",
    "\n",
    "            for i, channel in enumerate(channels):\n",
    "                channel_subset = channel_data[channel_data[\"channel\"] == channel]\n",
    "                heights = [\n",
    "                    (\n",
    "                        channel_subset[channel_subset[\"card_directory\"] == d][\n",
    "                            \"expected_50.0\"\n",
    "                        ].values[0]\n",
    "                        if len(channel_subset[channel_subset[\"card_directory\"] == d]) > 0\n",
    "                        else 0\n",
    "                    )\n",
    "                    for d in directories\n",
    "                ]\n",
    "\n",
    "                ax2.bar(x + i * width, heights, width, label=channel, color=colors[i], alpha=0.8)\n",
    "\n",
    "            ax2.set_xlabel(\"Analysis Directory\")\n",
    "            ax2.set_ylabel(\"Expected Limit (r < X)\")\n",
    "            ax2.set_title(\"Expected Limits by Analysis\", fontsize=14)\n",
    "            ax2.set_xticks(x + width * (len(channels) - 1) / 2)\n",
    "            ax2.set_xticklabels(\n",
    "                [d[:10] + \"...\" if len(d) > 10 else d for d in directories], rotation=45, ha=\"right\"\n",
    "            )\n",
    "            ax2.legend(fontsize=10)\n",
    "            hep.cms.label(loc=0, ax=ax2, fontsize=10)\n",
    "        else:\n",
    "            ax2.text(\n",
    "                0.5,\n",
    "                0.5,\n",
    "                \"Single analysis directory\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                transform=ax2.transAxes,\n",
    "                fontsize=12,\n",
    "            )\n",
    "            ax2.set_title(\"Expected Limits by Analysis\", fontsize=14)\n",
    "\n",
    "    # 3. Limit bands visualization\n",
    "    ax3 = axes[1, 0]\n",
    "    band_cols = [\"expected_2.5\", \"expected_16.0\", \"expected_50.0\", \"expected_84.0\", \"expected_97.5\"]\n",
    "    available_bands = [col for col in band_cols if col in results_df.columns]\n",
    "\n",
    "    if len(available_bands) >= 3:\n",
    "        # Show bands for combined channel\n",
    "        combined_data = results_df[results_df[\"channel\"] == \"combined\"].dropna(\n",
    "            subset=available_bands\n",
    "        )\n",
    "        if len(combined_data) > 0:\n",
    "            x_pos = range(len(combined_data))\n",
    "            labels = [f\"{d[:15]}...\" if len(d) > 15 else d for d in combined_data[\"card_directory\"]]\n",
    "\n",
    "            # Plot central value and error bands\n",
    "            ax3.errorbar(\n",
    "                x_pos,\n",
    "                combined_data[\"expected_50.0\"],\n",
    "                yerr=[\n",
    "                    combined_data[\"expected_50.0\"]\n",
    "                    - combined_data.get(\"expected_16.0\", combined_data[\"expected_50.0\"]),\n",
    "                    combined_data.get(\"expected_84.0\", combined_data[\"expected_50.0\"])\n",
    "                    - combined_data[\"expected_50.0\"],\n",
    "                ],\n",
    "                fmt=\"o-\",\n",
    "                capsize=5,\n",
    "                capthick=2,\n",
    "                color=\"black\",\n",
    "                linewidth=2,\n",
    "                markersize=6,\n",
    "            )\n",
    "\n",
    "            # Add 2œÉ band if available\n",
    "            if \"expected_2.5\" in combined_data.columns and \"expected_97.5\" in combined_data.columns:\n",
    "                ax3.fill_between(\n",
    "                    x_pos,\n",
    "                    combined_data[\"expected_2.5\"],\n",
    "                    combined_data[\"expected_97.5\"],\n",
    "                    alpha=0.3,\n",
    "                    color=\"yellow\",\n",
    "                    label=\"Expected ¬±2œÉ\",\n",
    "                )\n",
    "\n",
    "            # Add 1œÉ band if available\n",
    "            if (\n",
    "                \"expected_16.0\" in combined_data.columns\n",
    "                and \"expected_84.0\" in combined_data.columns\n",
    "            ):\n",
    "                ax3.fill_between(\n",
    "                    x_pos,\n",
    "                    combined_data[\"expected_16.0\"],\n",
    "                    combined_data[\"expected_84.0\"],\n",
    "                    alpha=0.5,\n",
    "                    color=\"green\",\n",
    "                    label=\"Expected ¬±1œÉ\",\n",
    "                )\n",
    "\n",
    "            ax3.plot(\n",
    "                x_pos,\n",
    "                combined_data[\"expected_50.0\"],\n",
    "                \"o-\",\n",
    "                color=\"black\",\n",
    "                linewidth=2,\n",
    "                markersize=6,\n",
    "                label=\"Expected median\",\n",
    "            )\n",
    "\n",
    "            ax3.set_xticks(x_pos)\n",
    "            ax3.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "            ax3.set_title(\"Expected Limit Bands (Combined Channel)\", fontsize=14)\n",
    "            ax3.set_ylabel(\"Expected Limit (r < X)\", fontsize=12)\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "            ax3.legend(fontsize=10)\n",
    "            hep.cms.label(loc=0, ax=ax3, fontsize=10)\n",
    "\n",
    "    # 4. Status overview\n",
    "    ax4 = axes[1, 1]\n",
    "    if \"status\" in results_df.columns:\n",
    "        status_counts = results_df[\"status\"].value_counts()\n",
    "        colors = [\n",
    "            \"#2E8B57\" if s == \"success\" else \"#FF8C00\" if s == \"issues\" else \"#DC143C\"\n",
    "            for s in status_counts.index\n",
    "        ]\n",
    "        wedges, texts, autotexts = ax4.pie(\n",
    "            status_counts.values,\n",
    "            labels=status_counts.index,\n",
    "            autopct=\"%1.1f%%\",\n",
    "            colors=colors,\n",
    "            startangle=90,\n",
    "        )\n",
    "        ax4.set_title(\"Analysis Status Overview\", fontsize=14)\n",
    "        # Make percentage text more readable\n",
    "        for autotext in autotexts:\n",
    "            autotext.set_color(\"white\")\n",
    "            autotext.set_fontweight(\"bold\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient data for plotting\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Issues and Warnings Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify problematic analyses\n",
    "print(\"=== ISSUES AND WARNINGS REPORT ===\")\n",
    "\n",
    "# Convergence issues\n",
    "if \"fit_converged\" in results_df.columns:\n",
    "    non_converged = results_df[results_df[\"fit_converged\"] == False]\n",
    "    if len(non_converged) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  NON-CONVERGED BACKGROUND FITS ({len(non_converged)})\")\n",
    "        for _, row in non_converged.iterrows():\n",
    "            print(f\"  - {row['card_directory']} / {row['channel']}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ All background fits converged\")\n",
    "\n",
    "# Limit calculation issues\n",
    "if \"status\" in results_df.columns:\n",
    "    failed_limits = results_df[results_df[\"status\"] != \"success\"]\n",
    "    if len(failed_limits) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  LIMIT CALCULATION ISSUES ({len(failed_limits)})\")\n",
    "        for _, row in failed_limits.iterrows():\n",
    "            issues = \", \".join(row.get(\"convergence_issues\", []))\n",
    "            print(f\"  - {row['card_directory']} / {row['channel']}: {row['status']} ({issues})\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ All limit calculations successful\")\n",
    "\n",
    "# Outlier limits (unusually high or low)\n",
    "if \"expected_50.0\" in results_df.columns:\n",
    "    valid_limits = results_df.dropna(subset=[\"expected_50.0\"])\n",
    "    if len(valid_limits) > 1:\n",
    "        Q1 = valid_limits[\"expected_50.0\"].quantile(0.25)\n",
    "        Q3 = valid_limits[\"expected_50.0\"].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = valid_limits[\n",
    "            (valid_limits[\"expected_50.0\"] < lower_bound)\n",
    "            | (valid_limits[\"expected_50.0\"] > upper_bound)\n",
    "        ]\n",
    "\n",
    "        if len(outliers) > 0:\n",
    "            print(f\"\\nüìä OUTLIER LIMITS ({len(outliers)})\")\n",
    "            print(f\"   Normal range: {lower_bound:.3f} - {upper_bound:.3f}\")\n",
    "            for _, row in outliers.iterrows():\n",
    "                print(f\"  - {row['card_directory']} / {row['channel']}: {row['expected_50.0']:.3f}\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ No outlier limits detected\")\n",
    "\n",
    "# Function call warnings\n",
    "if \"function_calls\" in results_df.columns:\n",
    "    high_calls = results_df[results_df[\"function_calls\"] > 10000]  # Arbitrary threshold\n",
    "    if len(high_calls) > 0:\n",
    "        print(f\"\\n‚è±Ô∏è  HIGH FUNCTION CALL COUNT ({len(high_calls)})\")\n",
    "        for _, row in high_calls.iterrows():\n",
    "            print(f\"  - {row['card_directory']} / {row['channel']}: {row['function_calls']} calls\")\n",
    "\n",
    "print(\"\\n=== END REPORT ===\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Export Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV for further analysis\n",
    "output_file = Path(CARDS_BASE_DIR) / \"analysis_results_summary.csv\"\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to: {output_file}\")\n",
    "\n",
    "# Create a summary report\n",
    "report_file = Path(CARDS_BASE_DIR) / \"analysis_report.txt\"\n",
    "with open(report_file, \"w\") as f:\n",
    "    f.write(\"HiggsCombine Analysis Report\\n\")\n",
    "    f.write(\"=\" * 30 + \"\\n\\n\")\n",
    "\n",
    "    f.write(f\"Generated: {pd.Timestamp.now()}\\n\\n\")\n",
    "\n",
    "    f.write(\"SUMMARY:\\n\")\n",
    "    f.write(f\"- Total analyses: {len(results_df)}\\n\")\n",
    "    f.write(f\"- Card directories: {results_df['card_directory'].nunique()}\\n\")\n",
    "    f.write(f\"- Channels: {', '.join(sorted(results_df['channel'].unique()))}\\n\\n\")\n",
    "\n",
    "    if \"expected_50.0\" in results_df.columns:\n",
    "        combined_limits = results_df[results_df[\"channel\"] == \"combined\"][\"expected_50.0\"].dropna()\n",
    "        if len(combined_limits) > 0:\n",
    "            f.write(\"COMBINED CHANNEL EXPECTED LIMITS:\\n\")\n",
    "            f.write(f\"- Best limit: {combined_limits.min():.3f}\\n\")\n",
    "            f.write(f\"- Median limit: {combined_limits.median():.3f}\\n\")\n",
    "            f.write(f\"- Worst limit: {combined_limits.max():.3f}\\n\\n\")\n",
    "\n",
    "    if \"fit_converged\" in results_df.columns:\n",
    "        conv_rate = results_df[\"fit_converged\"].sum() / len(results_df) * 100\n",
    "        f.write(f\"CONVERGENCE RATE: {conv_rate:.1f}%\\n\\n\")\n",
    "\n",
    "    f.write(\"DETAILED RESULTS: See analysis_results_summary.csv\\n\")\n",
    "\n",
    "print(f\"Summary report saved to: {report_file}\")\n",
    "print(\"\\nüìÅ Output files created:\")\n",
    "print(f\"  - {output_file.name}\")\n",
    "print(f\"  - {report_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
